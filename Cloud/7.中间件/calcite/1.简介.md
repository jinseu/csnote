First, we define a schema based on a schema factory class in a model file. 
Then the schema factory creates a schema, 
and the schema creates several tables, each of which knows how to get data by scanning a CSV file. 
Last, after Calcite has parsed the query and planned it to use those tables, Calcite invokes the tables to read the data as the query is being executed.



https://docs.oracle.com/javase/specs/jls/se8/html/jls-9.html#jls-9.7.4
https://checkerframework.org/


https://hc.apache.org/httpcomponents-client-5.1.x/quickstart.html


https://cwiki.apache.org/confluence/display/FLINK/FLIP-1+%3A+Fine+Grained+Recovery+from+Task+Failures

https://ci.apache.org/projects/flink/flink-docs-master/docs/dev/table/data_stream_api/